version: "3.9"

services:
  tgi:
    image: ghcr.io/huggingface/text-generation-inference:latest
    container_name: tgi
    restart: unless-stopped
    ports:
      - "8080:80"
    environment:
      - MODEL_ID=${MODEL_ID}
      - NUM_SHARD=${NUM_SHARD}
      - MAX_INPUT_LENGTH=${MAX_INPUT_LENGTH}
      - MAX_TOTAL_TOKENS=${MAX_TOTAL_TOKENS}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    volumes:
      - hf-cache:/data  # stores models on disk for reuse

volumes:
  hf-cache:
